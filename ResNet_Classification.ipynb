{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9993b1b",
   "metadata": {},
   "source": [
    "# Recreating \" Melanoma diagnosis using deep learning techniques on dermatoscopic images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601309c",
   "metadata": {},
   "source": [
    "## Imports and Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a5275",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f79d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "#import torchvision\n",
    "#import torchvision.transforms.v2 as v2\n",
    "#from torchvision.transforms.v2 import Lambda\n",
    "#from torchvision.utils import draw_bounding_boxes\n",
    "from torch.utils.data import  DataLoader\n",
    "from dataloader import ISICClassImageDataset\n",
    "from transforms import dataTransforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "device = torch.device(device)\n",
    "\n",
    "from torchvision.models import ResNet152_Weights\n",
    "from torchvision.models import resnet152\n",
    "weights = ResNet152_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f02d6",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8ec638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "#constants:\n",
    "batch_size = 64\n",
    "data_aug_type = \"1\" #what data augmentation schema to train on\n",
    "dataset = \"Dataset_2017\\\\\"\n",
    "size=(224,224)\n",
    "transforms = dataTransforms(data_aug_type,size=size,mask=False)\n",
    "\n",
    "\n",
    "Train_Dataset      = ISICClassImageDataset(dataset,\"Training\",data_aug_type=data_aug_type,size=size,bb_data_type=data_aug_type)#, target_transform=Lambda(lambda y: torch.zeros( 2, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y,dtype=torch.int64), value=1)),size=size)\n",
    "Validation_Dataset = ISICClassImageDataset(dataset,\"Validation\",data_aug_type=\"1\", size=size,bb_data_type=data_aug_type)\n",
    "Test_Dataset       = ISICClassImageDataset(dataset,\"Test\",data_aug_type=\"1\", size=size,bb_data_type=data_aug_type)\n",
    "\n",
    "data_loader_params = {\n",
    "    'batch_size': batch_size,  # Batch size for data loading\n",
    "    'num_workers': 10,  # Number of subprocesses to use for data loading\n",
    "    'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n",
    "    'pin_memory': True,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n",
    "    'pin_memory_device': 'cuda' ,  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n",
    "}\n",
    "train_dataloader      = DataLoader(Train_Dataset, **data_loader_params, shuffle=True)\n",
    "validation_dataloader = DataLoader(Validation_Dataset, **data_loader_params, shuffle=True)\n",
    "test_dataloader       = DataLoader(Test_Dataset, **data_loader_params, shuffle=False,in_order=True)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13be7a3",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd0f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_FREQUENCY = 10\n",
    "def train_one_epoch(model, training_loader, epoch_index, loss_fn, tb_writer, optimizer, lr_scheduler, scaler= None):\n",
    "    \"\"\"\n",
    "    This function will train your model and save the one that perfroms the best of validation data  \n",
    "    model: the model you wish to test  \n",
    "    train_loader: the data loader of the training dataset  \n",
    "    epoch_index: what epoch we are in for reporting purposes  \n",
    "    loss_fn: your chose loss function  \n",
    "    tb_writer: a summaryWriter used for tracking our training  \n",
    "    optimizer: the algorthim to step toward the optimal solution  \n",
    "    lr_scheduler: the lr_scheduler changes the lr dynamically as needed  \n",
    "    scaler: scales the loss dues to our use of mixed precision  \n",
    "    \"\"\"\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, targets = data\n",
    "        #send them to the model's device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #use automatic mixed precision to reduce memory consumption and allow us to run on more limited resources\n",
    "        with torch.amp.autocast(torch.device(device).type):\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        running_loss += loss\n",
    "        if scaler:#if were scaling our loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            old_scaler = scaler.get_scale()\n",
    "            scaler.update()\n",
    "            new_scaler = scaler.get_scale()\n",
    "            if new_scaler >= old_scaler:\n",
    "                lr_scheduler.step()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        \n",
    "        if i % REPORT_FREQUENCY == REPORT_FREQUENCY-1:\n",
    "            last_loss = running_loss / i # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a3893",
   "metadata": {},
   "source": [
    "## ResNet initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749b05c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet_model_train = True\n",
    "loss_weight = 0.8\n",
    "ResNet_model_path = 'Trained_Models\\\\ResNet152_Best_{}_{}'.format(data_aug_type,loss_weight)\n",
    "lr = 0.001\n",
    "EPOCHS = 100\n",
    "ResNet_model = resnet152(weights=weights, progress=False)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([1-loss_weight,loss_weight],device=device))\n",
    "ResNet_model.fc = nn.Linear(in_features=2048,out_features=2,bias=True)#change our number of classes to 2\n",
    "optimizer = torch.optim.SGD(ResNet_model.parameters(), lr=lr,weight_decay=0.000001)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=EPOCHS*len(train_dataloader))\n",
    "ResNet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2e2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 10 loss: 0.24414189159870148\n",
      "  batch 20 loss: 0.2350095510482788\n",
      "  batch 30 loss: 0.22814828157424927\n",
      "LOSS train 0.22814828157424927 valid 0.21063128113746643\n",
      "Accuracy: 0.6266666666666667 Balanced Accuracy: 0.5694444444208333\n",
      "EPOCH 2:\n",
      "  batch 10 loss: 0.2481740266084671\n",
      "  batch 20 loss: 0.22556659579277039\n",
      "  batch 30 loss: 0.21719947457313538\n",
      "LOSS train 0.21719947457313538 valid 0.21028491854667664\n",
      "Accuracy: 0.7 Balanced Accuracy: 0.5805549339510394\n",
      "EPOCH 3:\n",
      "  batch 10 loss: 0.23136867582798004\n",
      "  batch 20 loss: 0.2133502960205078\n",
      "  batch 30 loss: 0.21042664349079132\n",
      "LOSS train 0.21042664349079132 valid 0.20578329265117645\n",
      "Accuracy: 0.6733333333333333 Balanced Accuracy: 0.6004784688697695\n",
      "EPOCH 4:\n",
      "  batch 10 loss: 0.2173038274049759\n",
      "  batch 20 loss: 0.20313362777233124\n",
      "  batch 30 loss: 0.20197269320487976\n",
      "LOSS train 0.20197269320487976 valid 0.20735524594783783\n",
      "Accuracy: 0.64 Balanced Accuracy: 0.5981104650918649\n",
      "EPOCH 5:\n",
      "  batch 10 loss: 0.2021707445383072\n",
      "  batch 20 loss: 0.197839617729187\n",
      "  batch 30 loss: 0.1927972137928009\n",
      "LOSS train 0.1927972137928009 valid 0.1900598257780075\n",
      "Accuracy: 0.7 Balanced Accuracy: 0.6491987474363996\n",
      "EPOCH 6:\n",
      "  batch 10 loss: 0.19975709915161133\n",
      "  batch 20 loss: 0.1954914927482605\n",
      "  batch 30 loss: 0.18841737508773804\n",
      "LOSS train 0.18841737508773804 valid 0.18467378616333008\n",
      "Accuracy: 0.6533333333333333 Balanced Accuracy: 0.6190476190223665\n",
      "EPOCH 7:\n",
      "  batch 10 loss: 0.17884357273578644\n",
      "  batch 20 loss: 0.17436686158180237\n",
      "  batch 30 loss: 0.17944063246250153\n",
      "LOSS train 0.17944063246250153 valid 0.18628975749015808\n",
      "Accuracy: 0.6866666666666666 Balanced Accuracy: 0.635384048598178\n",
      "EPOCH 8:\n",
      "  batch 10 loss: 0.17210248112678528\n",
      "  batch 20 loss: 0.17527885735034943\n",
      "  batch 30 loss: 0.16984906792640686\n",
      "LOSS train 0.16984906792640686 valid 0.19282500445842743\n",
      "Accuracy: 0.6866666666666666 Balanced Accuracy: 0.635384048598178\n",
      "EPOCH 9:\n",
      "  batch 10 loss: 0.15956459939479828\n",
      "  batch 20 loss: 0.16030043363571167\n",
      "  batch 30 loss: 0.1614599972963333\n",
      "LOSS train 0.1614599972963333 valid 0.20390824973583221\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6961835333934489\n",
      "EPOCH 10:\n",
      "  batch 10 loss: 0.15205056965351105\n",
      "  batch 20 loss: 0.15067270398139954\n",
      "  batch 30 loss: 0.14494340121746063\n",
      "LOSS train 0.14494340121746063 valid 0.20410053431987762\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.687499999940625\n",
      "EPOCH 11:\n",
      "  batch 10 loss: 0.13226602971553802\n",
      "  batch 20 loss: 0.13590197265148163\n",
      "  batch 30 loss: 0.13390257954597473\n",
      "LOSS train 0.13390257954597473 valid 0.17410695552825928\n",
      "Accuracy: 0.7733333333333333 Balanced Accuracy: 0.6801029159003197\n",
      "EPOCH 12:\n",
      "  batch 10 loss: 0.12894101440906525\n",
      "  batch 20 loss: 0.13452240824699402\n",
      "  batch 30 loss: 0.12679681181907654\n",
      "LOSS train 0.12679681181907654 valid 0.20439794659614563\n",
      "Accuracy: 0.7533333333333333 Balanced Accuracy: 0.642065142012545\n",
      "EPOCH 13:\n",
      "  batch 10 loss: 0.12118919938802719\n",
      "  batch 20 loss: 0.12128125876188278\n",
      "  batch 30 loss: 0.12441603094339371\n",
      "LOSS train 0.12441603094339371 valid 0.22612535953521729\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.7020202019421486\n",
      "EPOCH 14:\n",
      "  batch 10 loss: 0.11882416158914566\n",
      "  batch 20 loss: 0.11645784974098206\n",
      "  batch 30 loss: 0.11273708194494247\n",
      "LOSS train 0.11273708194494247 valid 0.17957380414009094\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6749492899916478\n",
      "EPOCH 15:\n",
      "  batch 10 loss: 0.10838346183300018\n",
      "  batch 20 loss: 0.10200099647045135\n",
      "  batch 30 loss: 0.0925067737698555\n",
      "LOSS train 0.0925067737698555 valid 0.22781233489513397\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7304025422849907\n",
      "EPOCH 16:\n",
      "  batch 10 loss: 0.07306960225105286\n",
      "  batch 20 loss: 0.06965044140815735\n",
      "  batch 30 loss: 0.06699449568986893\n",
      "LOSS train 0.06699449568986893 valid 0.2941395044326782\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7024147726033058\n",
      "EPOCH 17:\n",
      "  batch 10 loss: 0.058592069894075394\n",
      "  batch 20 loss: 0.05818791314959526\n",
      "  batch 30 loss: 0.059069808572530746\n",
      "LOSS train 0.059069808572530746 valid 0.2611643075942993\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7393857270808659\n",
      "EPOCH 18:\n",
      "  batch 10 loss: 0.046484675258398056\n",
      "  batch 20 loss: 0.04172443598508835\n",
      "  batch 30 loss: 0.03880120813846588\n",
      "LOSS train 0.03880120813846588 valid 0.2607017457485199\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6942186087567332\n",
      "EPOCH 19:\n",
      "  batch 10 loss: 0.03373383730649948\n",
      "  batch 20 loss: 0.028629884123802185\n",
      "  batch 30 loss: 0.030621150508522987\n",
      "LOSS train 0.030621150508522987 valid 0.33829259872436523\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7512406946707386\n",
      "EPOCH 20:\n",
      "  batch 10 loss: 0.023953644558787346\n",
      "  batch 20 loss: 0.022157270461320877\n",
      "  batch 30 loss: 0.023672621697187424\n",
      "LOSS train 0.023672621697187424 valid 0.31237703561782837\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.684426229418911\n",
      "EPOCH 21:\n",
      "  batch 10 loss: 0.06649097800254822\n",
      "  batch 20 loss: 0.06328703463077545\n",
      "  batch 30 loss: 0.06670373678207397\n",
      "LOSS train 0.06670373678207397 valid 0.25761649012565613\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6966372184916128\n",
      "EPOCH 22:\n",
      "  batch 10 loss: 0.04565982520580292\n",
      "  batch 20 loss: 0.04055763781070709\n",
      "  batch 30 loss: 0.036904726177453995\n",
      "LOSS train 0.036904726177453995 valid 0.4529840648174286\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.73999999988\n",
      "EPOCH 23:\n",
      "  batch 10 loss: 0.026460668072104454\n",
      "  batch 20 loss: 0.023866964504122734\n",
      "  batch 30 loss: 0.02380439080297947\n",
      "LOSS train 0.02380439080297947 valid 0.3228985667228699\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.6973684209831872\n",
      "EPOCH 24:\n",
      "  batch 10 loss: 0.01978362537920475\n",
      "  batch 20 loss: 0.01966918259859085\n",
      "  batch 30 loss: 0.01916627027094364\n",
      "LOSS train 0.01916627027094364 valid 0.2500549256801605\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.772248243444923\n",
      "EPOCH 25:\n",
      "  batch 10 loss: 0.016287965700030327\n",
      "  batch 20 loss: 0.013893651776015759\n",
      "  batch 30 loss: 0.014693115837872028\n",
      "LOSS train 0.014693115837872028 valid 0.4713281989097595\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7047146400949609\n",
      "EPOCH 26:\n",
      "  batch 10 loss: 0.015347463078796864\n",
      "  batch 20 loss: 0.011775764636695385\n",
      "  batch 30 loss: 0.010220358148217201\n",
      "LOSS train 0.010220358148217201 valid 0.2948681116104126\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.728337236431917\n",
      "EPOCH 27:\n",
      "  batch 10 loss: 0.010541076771914959\n",
      "  batch 20 loss: 0.011943811550736427\n",
      "  batch 30 loss: 0.012052695266902447\n",
      "LOSS train 0.012052695266902447 valid 0.3781092166900635\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.7884615382865384\n",
      "EPOCH 28:\n",
      "  batch 10 loss: 0.006798467133194208\n",
      "  batch 20 loss: 0.008218623697757721\n",
      "  batch 30 loss: 0.007826284505426884\n",
      "LOSS train 0.007826284505426884 valid 0.49277493357658386\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.73999999988\n",
      "EPOCH 29:\n",
      "  batch 10 loss: 0.004858067259192467\n",
      "  batch 20 loss: 0.0059790341183543205\n",
      "  batch 30 loss: 0.006582280155271292\n",
      "LOSS train 0.006582280155271292 valid 0.3787233531475067\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.728337236431917\n",
      "EPOCH 30:\n",
      "  batch 10 loss: 0.0073367697186768055\n",
      "  batch 20 loss: 0.010904913768172264\n",
      "  batch 30 loss: 0.014165760949254036\n",
      "LOSS train 0.014165760949254036 valid 0.5049945116043091\n",
      "Accuracy: 0.7933333333333333 Balanced Accuracy: 0.6716350495946669\n",
      "EPOCH 31:\n",
      "  batch 10 loss: 0.06995455920696259\n",
      "  batch 20 loss: 0.07141610234975815\n",
      "  batch 30 loss: 0.08398789167404175\n",
      "LOSS train 0.08398789167404175 valid 0.45007914304733276\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.684426229418911\n",
      "EPOCH 32:\n",
      "  batch 10 loss: 0.0782332494854927\n",
      "  batch 20 loss: 0.06622863560914993\n",
      "  batch 30 loss: 0.06837663054466248\n",
      "LOSS train 0.06837663054466248 valid 0.2649787664413452\n",
      "Accuracy: 0.7666666666666667 Balanced Accuracy: 0.6490683229201419\n",
      "EPOCH 33:\n",
      "  batch 10 loss: 0.047648835927248\n",
      "  batch 20 loss: 0.04516316577792168\n",
      "  batch 30 loss: 0.04361124709248543\n",
      "LOSS train 0.04361124709248543 valid 0.30688416957855225\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7185150375247329\n",
      "EPOCH 34:\n",
      "  batch 10 loss: 0.023717503994703293\n",
      "  batch 20 loss: 0.021452317014336586\n",
      "  batch 30 loss: 0.02167658321559429\n",
      "LOSS train 0.02167658321559429 valid 0.3684609532356262\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.7607580506196874\n",
      "EPOCH 35:\n",
      "  batch 10 loss: 0.0201142355799675\n",
      "  batch 20 loss: 0.019427765160799026\n",
      "  batch 30 loss: 0.017187021672725677\n",
      "LOSS train 0.017187021672725677 valid 0.4023488461971283\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.7777777776388888\n",
      "EPOCH 36:\n",
      "  batch 10 loss: 0.020548498257994652\n",
      "  batch 20 loss: 0.023579342290759087\n",
      "  batch 30 loss: 0.024506226181983948\n",
      "LOSS train 0.024506226181983948 valid 0.3213934898376465\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7281746030530754\n",
      "EPOCH 37:\n",
      "  batch 10 loss: 0.015025225467979908\n",
      "  batch 20 loss: 0.016657741740345955\n",
      "  batch 30 loss: 0.018572097644209862\n",
      "LOSS train 0.018572097644209862 valid 0.45013827085494995\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.75568181803719\n",
      "EPOCH 38:\n",
      "  batch 10 loss: 0.008629193529486656\n",
      "  batch 20 loss: 0.009452772326767445\n",
      "  batch 30 loss: 0.009248646907508373\n",
      "LOSS train 0.009248646907508373 valid 0.42402562499046326\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7168021679187995\n",
      "EPOCH 39:\n",
      "  batch 10 loss: 0.006897374987602234\n",
      "  batch 20 loss: 0.006769530009478331\n",
      "  batch 30 loss: 0.0064193690195679665\n",
      "LOSS train 0.0064193690195679665 valid 0.3361806273460388\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.763999999872\n",
      "EPOCH 40:\n",
      "  batch 10 loss: 0.007503320928663015\n",
      "  batch 20 loss: 0.005623245611786842\n",
      "  batch 30 loss: 0.005909309722483158\n",
      "LOSS train 0.005909309722483158 valid 0.4301133155822754\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7413556999703794\n",
      "EPOCH 41:\n",
      "  batch 10 loss: 0.0037294880021363497\n",
      "  batch 20 loss: 0.004835132509469986\n",
      "  batch 30 loss: 0.004838849883526564\n",
      "LOSS train 0.004838849883526564 valid 0.3930656909942627\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 42:\n",
      "  batch 10 loss: 0.004039389081299305\n",
      "  batch 20 loss: 0.004618407692760229\n",
      "  batch 30 loss: 0.0045311166904866695\n",
      "LOSS train 0.0045311166904866695 valid 0.39763888716697693\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7529761903459822\n",
      "EPOCH 43:\n",
      "  batch 10 loss: 0.0022665602155029774\n",
      "  batch 20 loss: 0.003567148931324482\n",
      "  batch 30 loss: 0.004341305233538151\n",
      "LOSS train 0.004341305233538151 valid 0.34721824526786804\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6942186087567332\n",
      "EPOCH 44:\n",
      "  batch 10 loss: 0.004240519367158413\n",
      "  batch 20 loss: 0.004688491579145193\n",
      "  batch 30 loss: 0.004116792231798172\n",
      "LOSS train 0.004116792231798172 valid 0.5085739493370056\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7436323365082002\n",
      "EPOCH 45:\n",
      "  batch 10 loss: 0.004983632825314999\n",
      "  batch 20 loss: 0.005299449898302555\n",
      "  batch 30 loss: 0.004136465955525637\n",
      "LOSS train 0.004136465955525637 valid 0.4503926634788513\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.7777777776388888\n",
      "EPOCH 46:\n",
      "  batch 10 loss: 0.003352063475176692\n",
      "  batch 20 loss: 0.0038794055581092834\n",
      "  batch 30 loss: 0.004053977318108082\n",
      "LOSS train 0.004053977318108082 valid 0.38704419136047363\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.7670318382697259\n",
      "EPOCH 47:\n",
      "  batch 10 loss: 0.0015723775140941143\n",
      "  batch 20 loss: 0.0036981585435569286\n",
      "  batch 30 loss: 0.0041738105937838554\n",
      "LOSS train 0.0041738105937838554 valid 0.46363720297813416\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7436323365082002\n",
      "EPOCH 48:\n",
      "  batch 10 loss: 0.005118579138070345\n",
      "  batch 20 loss: 0.003999775741249323\n",
      "  batch 30 loss: 0.004101456608623266\n",
      "LOSS train 0.004101456608623266 valid 0.6014682650566101\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 49:\n",
      "  batch 10 loss: 0.00423392653465271\n",
      "  batch 20 loss: 0.0030229862313717604\n",
      "  batch 30 loss: 0.0036734763998538256\n",
      "LOSS train 0.0036734763998538256 valid 0.5552678108215332\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7651515149663299\n",
      "EPOCH 50:\n",
      "  batch 10 loss: 0.005073918495327234\n",
      "  batch 20 loss: 0.005163227207958698\n",
      "  batch 30 loss: 0.004768598824739456\n",
      "LOSS train 0.004768598824739456 valid 0.5392827987670898\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.7823153407541322\n",
      "EPOCH 51:\n",
      "  batch 10 loss: 0.003855794668197632\n",
      "  batch 20 loss: 0.004284060560166836\n",
      "  batch 30 loss: 0.0044161416590213776\n",
      "LOSS train 0.0044161416590213776 valid 0.39169013500213623\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7596153844528846\n",
      "EPOCH 52:\n",
      "  batch 10 loss: 0.0037257405929267406\n",
      "  batch 20 loss: 0.0039445688016712666\n",
      "  batch 30 loss: 0.0036328271962702274\n",
      "LOSS train 0.0036328271962702274 valid 0.49597740173339844\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7281746030530754\n",
      "EPOCH 53:\n",
      "  batch 10 loss: 0.004271521233022213\n",
      "  batch 20 loss: 0.004480245057493448\n",
      "  batch 30 loss: 0.00448243971914053\n",
      "LOSS train 0.00448243971914053 valid 0.4540262818336487\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7033730157601686\n",
      "EPOCH 54:\n",
      "  batch 10 loss: 0.0028434323612600565\n",
      "  batch 20 loss: 0.003552403999492526\n",
      "  batch 30 loss: 0.004194703884422779\n",
      "LOSS train 0.004194703884422779 valid 0.45498067140579224\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7728544773970966\n",
      "EPOCH 55:\n",
      "  batch 10 loss: 0.004552648868411779\n",
      "  batch 20 loss: 0.00426672725006938\n",
      "  batch 30 loss: 0.0037274640053510666\n",
      "LOSS train 0.0037274640053510666 valid 0.5588793158531189\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.785272003330645\n",
      "EPOCH 56:\n",
      "  batch 10 loss: 0.003454503370448947\n",
      "  batch 20 loss: 0.0031507175881415606\n",
      "  batch 30 loss: 0.0032745134085416794\n",
      "LOSS train 0.0032745134085416794 valid 0.5234726071357727\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7413556999703794\n",
      "EPOCH 57:\n",
      "  batch 10 loss: 0.004810410551726818\n",
      "  batch 20 loss: 0.004528796300292015\n",
      "  batch 30 loss: 0.0037867315113544464\n",
      "LOSS train 0.0037867315113544464 valid 0.4501084089279175\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.691999999896\n",
      "EPOCH 58:\n",
      "  batch 10 loss: 0.0032694325782358646\n",
      "  batch 20 loss: 0.0038047542329877615\n",
      "  batch 30 loss: 0.003433006117120385\n",
      "LOSS train 0.003433006117120385 valid 0.6048749685287476\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7413556999703794\n",
      "EPOCH 59:\n",
      "  batch 10 loss: 0.0026219545397907495\n",
      "  batch 20 loss: 0.0033165302593261003\n",
      "  batch 30 loss: 0.0034364687744528055\n",
      "LOSS train 0.0034364687744528055 valid 0.4779568910598755\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.785272003330645\n",
      "EPOCH 60:\n",
      "  batch 10 loss: 0.003105863695964217\n",
      "  batch 20 loss: 0.0030782895628362894\n",
      "  batch 30 loss: 0.003249902045354247\n",
      "LOSS train 0.003249902045354247 valid 0.5566738843917847\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7436323365082002\n",
      "EPOCH 61:\n",
      "  batch 10 loss: 0.0024044588208198547\n",
      "  batch 20 loss: 0.0029960640240460634\n",
      "  batch 30 loss: 0.0035105152055621147\n",
      "LOSS train 0.0035105152055621147 valid 0.4968183934688568\n",
      "Accuracy: 0.86 Balanced Accuracy: 0.8184431665154668\n",
      "EPOCH 62:\n",
      "  batch 10 loss: 0.0047197951935231686\n",
      "  batch 20 loss: 0.006863371469080448\n",
      "  batch 30 loss: 0.005545970983803272\n",
      "LOSS train 0.005545970983803272 valid 0.4317502975463867\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7281746030530754\n",
      "EPOCH 63:\n",
      "  batch 10 loss: 0.003402675734832883\n",
      "  batch 20 loss: 0.004083059728145599\n",
      "  batch 30 loss: 0.005775941535830498\n",
      "LOSS train 0.005775941535830498 valid 0.37407347559928894\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7393857270808659\n",
      "EPOCH 64:\n",
      "  batch 10 loss: 0.004170176573097706\n",
      "  batch 20 loss: 0.006032245233654976\n",
      "  batch 30 loss: 0.004856119863688946\n",
      "LOSS train 0.004856119863688946 valid 0.4295409619808197\n",
      "Accuracy: 0.8533333333333334 Balanced Accuracy: 0.7777777776388888\n",
      "EPOCH 65:\n",
      "  batch 10 loss: 0.003918314818292856\n",
      "  batch 20 loss: 0.00408951798453927\n",
      "  batch 30 loss: 0.004450262524187565\n",
      "LOSS train 0.004450262524187565 valid 0.5118903517723083\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7279776673828497\n",
      "EPOCH 66:\n",
      "  batch 10 loss: 0.004634106997400522\n",
      "  batch 20 loss: 0.00455762492492795\n",
      "  batch 30 loss: 0.004583657719194889\n",
      "LOSS train 0.004583657719194889 valid 0.4687897861003876\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7168021679187995\n",
      "EPOCH 67:\n",
      "  batch 10 loss: 0.005098635796457529\n",
      "  batch 20 loss: 0.005942865274846554\n",
      "  batch 30 loss: 0.005031258333474398\n",
      "LOSS train 0.005031258333474398 valid 0.44113385677337646\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7024147726033058\n",
      "EPOCH 68:\n",
      "  batch 10 loss: 0.0035276885610073805\n",
      "  batch 20 loss: 0.0036050337366759777\n",
      "  batch 30 loss: 0.0038407554384320974\n",
      "LOSS train 0.0038407554384320974 valid 0.6136095523834229\n",
      "Accuracy: 0.7933333333333333 Balanced Accuracy: 0.6605758581368981\n",
      "EPOCH 69:\n",
      "  batch 10 loss: 0.0034406210761517286\n",
      "  batch 20 loss: 0.003709063632413745\n",
      "  batch 30 loss: 0.004021497443318367\n",
      "LOSS train 0.004021497443318367 valid 0.5346801280975342\n",
      "Accuracy: 0.7933333333333333 Balanced Accuracy: 0.667999999904\n",
      "EPOCH 70:\n",
      "  batch 10 loss: 0.005318640265613794\n",
      "  batch 20 loss: 0.004114089068025351\n",
      "  batch 30 loss: 0.003874309128150344\n",
      "LOSS train 0.003874309128150344 valid 0.644687831401825\n",
      "Accuracy: 0.78 Balanced Accuracy: 0.6386511467729932\n",
      "EPOCH 71:\n",
      "  batch 10 loss: 0.004138271789997816\n",
      "  batch 20 loss: 0.0030049472115933895\n",
      "  batch 30 loss: 0.0033729870337992907\n",
      "LOSS train 0.0033729870337992907 valid 0.5819337368011475\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.6785714284672619\n",
      "EPOCH 72:\n",
      "  batch 10 loss: 0.003769394475966692\n",
      "  batch 20 loss: 0.0033306502737104893\n",
      "  batch 30 loss: 0.0036541789304465055\n",
      "LOSS train 0.0036541789304465055 valid 0.5372570753097534\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6537698411743551\n",
      "EPOCH 73:\n",
      "  batch 10 loss: 0.0037043823394924402\n",
      "  batch 20 loss: 0.003769897622987628\n",
      "  batch 30 loss: 0.003236200427636504\n",
      "LOSS train 0.003236200427636504 valid 0.6309553980827332\n",
      "Accuracy: 0.7933333333333333 Balanced Accuracy: 0.6643272850723397\n",
      "EPOCH 74:\n",
      "  batch 10 loss: 0.0016039309557527304\n",
      "  batch 20 loss: 0.0029789158143103123\n",
      "  batch 30 loss: 0.003232703311368823\n",
      "LOSS train 0.003232703311368823 valid 0.6273821592330933\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.6757812498863636\n",
      "EPOCH 75:\n",
      "  batch 10 loss: 0.0032171139027923346\n",
      "  batch 20 loss: 0.003258177312090993\n",
      "  batch 30 loss: 0.003461781656369567\n",
      "LOSS train 0.003461781656369567 valid 0.6069701910018921\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6882613509273321\n",
      "EPOCH 76:\n",
      "  batch 10 loss: 0.0020753892604261637\n",
      "  batch 20 loss: 0.003426166484132409\n",
      "  batch 30 loss: 0.004082194995135069\n",
      "LOSS train 0.004082194995135069 valid 0.4796599745750427\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.73999999988\n",
      "EPOCH 77:\n",
      "  batch 10 loss: 0.006737484131008387\n",
      "  batch 20 loss: 0.005919857416301966\n",
      "  batch 30 loss: 0.006169037893414497\n",
      "LOSS train 0.006169037893414497 valid 0.5483132600784302\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7063817329254141\n",
      "EPOCH 78:\n",
      "  batch 10 loss: 0.00534332450479269\n",
      "  batch 20 loss: 0.004951888229697943\n",
      "  batch 30 loss: 0.0045746187679469585\n",
      "LOSS train 0.0045746187679469585 valid 0.5373775959014893\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7047146400949609\n",
      "EPOCH 79:\n",
      "  batch 10 loss: 0.0024158272426575422\n",
      "  batch 20 loss: 0.003420583438128233\n",
      "  batch 30 loss: 0.004310728050768375\n",
      "LOSS train 0.004310728050768375 valid 0.43641459941864014\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.715999999888\n",
      "EPOCH 80:\n",
      "  batch 10 loss: 0.0017078641103580594\n",
      "  batch 20 loss: 0.0038441773504018784\n",
      "  batch 30 loss: 0.003960737027227879\n",
      "LOSS train 0.003960737027227879 valid 0.4986208379268646\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7159468437177662\n",
      "EPOCH 81:\n",
      "  batch 10 loss: 0.005146684590727091\n",
      "  batch 20 loss: 0.0040817903354763985\n",
      "  batch 30 loss: 0.0038663700688630342\n",
      "LOSS train 0.0038663700688630342 valid 0.5821021199226379\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7159468437177662\n",
      "EPOCH 82:\n",
      "  batch 10 loss: 0.005008104722946882\n",
      "  batch 20 loss: 0.004689166788011789\n",
      "  batch 30 loss: 0.003514166921377182\n",
      "LOSS train 0.003514166921377182 valid 0.4460947513580322\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.715999999888\n",
      "EPOCH 83:\n",
      "  batch 10 loss: 0.002619029488414526\n",
      "  batch 20 loss: 0.0024770861491560936\n",
      "  batch 30 loss: 0.003367379540577531\n",
      "LOSS train 0.003367379540577531 valid 0.565596878528595\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7159468437177662\n",
      "EPOCH 84:\n",
      "  batch 10 loss: 0.003722887020558119\n",
      "  batch 20 loss: 0.00450082216411829\n",
      "  batch 30 loss: 0.003585493192076683\n",
      "LOSS train 0.003585493192076683 valid 0.608579158782959\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6882613509273321\n",
      "EPOCH 85:\n",
      "  batch 10 loss: 0.004520348273217678\n",
      "  batch 20 loss: 0.00440401304513216\n",
      "  batch 30 loss: 0.0037446587812155485\n",
      "LOSS train 0.0037446587812155485 valid 0.6424586176872253\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7413556999703794\n",
      "EPOCH 86:\n",
      "  batch 10 loss: 0.0027071817312389612\n",
      "  batch 20 loss: 0.003029507352039218\n",
      "  batch 30 loss: 0.0035100169479846954\n",
      "LOSS train 0.0035100169479846954 valid 0.44046860933303833\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7019230767855769\n",
      "EPOCH 87:\n",
      "  batch 10 loss: 0.003372429870069027\n",
      "  batch 20 loss: 0.004006630275398493\n",
      "  batch 30 loss: 0.0037277245428413153\n",
      "LOSS train 0.0037277245428413153 valid 0.46646544337272644\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7529761903459822\n",
      "EPOCH 88:\n",
      "  batch 10 loss: 0.0037862667813897133\n",
      "  batch 20 loss: 0.0035568636376410723\n",
      "  batch 30 loss: 0.0033189093228429556\n",
      "LOSS train 0.0033189093228429556 valid 0.4902663230895996\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7156795616710329\n",
      "EPOCH 89:\n",
      "  batch 10 loss: 0.00470708915963769\n",
      "  batch 20 loss: 0.003645967459306121\n",
      "  batch 30 loss: 0.003718838095664978\n",
      "LOSS train 0.003718838095664978 valid 0.6267590522766113\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7024147726033058\n",
      "EPOCH 90:\n",
      "  batch 10 loss: 0.0043858313001692295\n",
      "  batch 20 loss: 0.0032410009298473597\n",
      "  batch 30 loss: 0.00313596916384995\n",
      "LOSS train 0.00313596916384995 valid 0.5846455097198486\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 91:\n",
      "  batch 10 loss: 0.0034914070274680853\n",
      "  batch 20 loss: 0.005257976241409779\n",
      "  batch 30 loss: 0.0038835308514535427\n",
      "LOSS train 0.0038835308514535427 valid 0.5606321096420288\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7019230767855769\n",
      "EPOCH 92:\n",
      "  batch 10 loss: 0.004269096534699202\n",
      "  batch 20 loss: 0.003053372958675027\n",
      "  batch 30 loss: 0.003393603954464197\n",
      "LOSS train 0.003393603954464197 valid 0.5366557240486145\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.6868220167357425\n",
      "EPOCH 93:\n",
      "  batch 10 loss: 0.0033378705848008394\n",
      "  batch 20 loss: 0.004130079410970211\n",
      "  batch 30 loss: 0.0036104002501815557\n",
      "LOSS train 0.0036104002501815557 valid 0.48914533853530884\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 94:\n",
      "  batch 10 loss: 0.00488533778116107\n",
      "  batch 20 loss: 0.0036563717294484377\n",
      "  batch 30 loss: 0.00345957325771451\n",
      "LOSS train 0.00345957325771451 valid 0.5483722686767578\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 95:\n",
      "  batch 10 loss: 0.004709626082330942\n",
      "  batch 20 loss: 0.003910450730472803\n",
      "  batch 30 loss: 0.003717093262821436\n",
      "LOSS train 0.003717093262821436 valid 0.5415253639221191\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 96:\n",
      "  batch 10 loss: 0.003919227514415979\n",
      "  batch 20 loss: 0.0038926275447010994\n",
      "  batch 30 loss: 0.003782419255003333\n",
      "LOSS train 0.003782419255003333 valid 0.5446712970733643\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 97:\n",
      "  batch 10 loss: 0.002511332742869854\n",
      "  batch 20 loss: 0.003731261473149061\n",
      "  batch 30 loss: 0.003503207815811038\n",
      "LOSS train 0.003503207815811038 valid 0.4462820291519165\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7156795616710329\n",
      "EPOCH 98:\n",
      "  batch 10 loss: 0.004057258367538452\n",
      "  batch 20 loss: 0.003969324287027121\n",
      "  batch 30 loss: 0.003375022206455469\n",
      "LOSS train 0.003375022206455469 valid 0.5161088705062866\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.729048295320248\n",
      "EPOCH 99:\n",
      "  batch 10 loss: 0.002772801322862506\n",
      "  batch 20 loss: 0.0034905809443444014\n",
      "  batch 30 loss: 0.0034996008034795523\n",
      "LOSS train 0.0034996008034795523 valid 0.5945595502853394\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7159468437177662\n",
      "EPOCH 100:\n",
      "  batch 10 loss: 0.0024757885839790106\n",
      "  batch 20 loss: 0.0027737251948565245\n",
      "  batch 30 loss: 0.003443756140768528\n",
      "LOSS train 0.003443756140768528 valid 0.5339792370796204\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7024147726033058\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "if ResNet_model_train:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter('runs/ResNet{}'.format(timestamp))\n",
    "    epoch_number = 0\n",
    "\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        ResNet_model.train(True)\n",
    "        avg_loss = train_one_epoch(ResNet_model, train_dataloader, epoch_number, loss_fn, writer,optimizer,lr_scheduler,scaler)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        best_acc = 0.0\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        true_malig = 0.0\n",
    "        true_benign = 0.0\n",
    "        total_malig = 0.00000001 #prevent divide by zero\n",
    "        total_benign = 0.0          \n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        ResNet_model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_dataloader):\n",
    "                vinputs, vtargets = vdata\n",
    "                vinputs = vinputs.to(device)\n",
    "                vtargets = vtargets.to(device)\n",
    "                #again were using AMP to allow us to train faster\n",
    "                with torch.amp.autocast(torch.device(device).type):\n",
    "                    voutputs = ResNet_model(vinputs)\n",
    "                    vloss = loss_fn(voutputs,vtargets)\n",
    "                    running_vloss += vloss\n",
    "                    _, preds = voutputs.max(1)\n",
    "                    _, vtarget = vtargets.max(1)\n",
    "                #print((preds == vtarget).sum(), preds.size(0))\n",
    "                num_correct += (preds == vtarget).sum()\n",
    "                num_samples += preds.size(0)\n",
    "                true_malig   += torch.sum(((preds == 1.0) & (vtarget == 1.0))).item()\n",
    "                true_benign  += torch.sum(((preds == 0.0) & (vtarget == 0.0))).item()\n",
    "                total_malig  += torch.sum(preds == 1.0).item()\n",
    "                total_benign += torch.sum(preds == 0.0).item()\n",
    "                #print(true_benign,total_benign)\n",
    "                #print(true_malig,total_malig)\n",
    "                \n",
    "                \n",
    "        acc = float(num_correct) / num_samples\n",
    "        bal_acc = 0.5*((true_malig/total_malig)+(true_benign/total_benign))\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "        print('Accuracy:', acc, \"Balanced Accuracy:\", bal_acc)\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.add_scalar(\"Balanced Accuracy\",bal_acc,epoch_number+1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        #AKA early stopping, a form of regularization we talked about it class\n",
    "        if bal_acc > best_acc:\n",
    "            best_acc = bal_acc\n",
    "            torch.save(ResNet_model.state_dict(), \"{}\".format(ResNet_model_path))\n",
    "\n",
    "        epoch_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7ed96",
   "metadata": {},
   "source": [
    "Here we can load our lowest loss model that we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2139721",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ResNet_model_train:\n",
    "    checkpoint = torch.load(ResNet_model_path)\n",
    "    ResNet_model.load_state_dict(checkpoint)\n",
    "    ResNet_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00fdd3b",
   "metadata": {},
   "source": [
    "### Testing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069e386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7916666666666666\n",
      "Balanced Accuracy: 0.662306164540524\n"
     ]
    }
   ],
   "source": [
    "ResNet_model.eval()\n",
    "running_loss = 0.0\n",
    "best_acc = 0.0\n",
    "num_correct = 0.0\n",
    "num_samples = 0.0\n",
    "true_malig = 0.0\n",
    "true_benign = 0.0\n",
    "total_malig = 0.0\n",
    "total_benign = 0.0\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(test_dataloader):\n",
    "        inputs, targets = vdata\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        #again were using AMP to allow us to train faster\n",
    "        outputs = ResNet_model(inputs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "        running_loss += loss\n",
    "        _, preds = outputs.max(1)\n",
    "        _, target = targets.max(1)\n",
    "        num_correct += torch.sum(preds == target).item()\n",
    "        num_samples += preds.size(0)\n",
    "        #print(((preds == 0.0) == (target == 0.0)) == 0.0)\n",
    "        true_malig   += torch.sum(((preds == 1.0) & (target == 1.0))).item()\n",
    "        true_benign  += torch.sum(((preds == 0.0) & (target == 0.0))).item()\n",
    "        total_malig  += torch.sum(preds == 1.0).item()\n",
    "        total_benign += torch.sum(preds == 0.0).item()\n",
    "    acc = (num_correct / num_samples)\n",
    "print('Accuracy:', acc)\n",
    "print('Balanced Accuracy:', 0.5*((true_malig/total_malig)+(true_benign/total_benign)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
