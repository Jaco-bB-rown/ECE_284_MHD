{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9993b1b",
   "metadata": {},
   "source": [
    "# Recreating \" Melanoma diagnosis using deep learning techniques on dermatoscopic images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601309c",
   "metadata": {},
   "source": [
    "## Imports and Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a5275",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f79d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "#import torchvision\n",
    "#import torchvision.transforms.v2 as v2\n",
    "#from torchvision.transforms.v2 import Lambda\n",
    "#from torchvision.utils import draw_bounding_boxes\n",
    "from torch.utils.data import  DataLoader\n",
    "from dataloader import ISICClassImageDataset\n",
    "from transforms import dataTransforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "device = torch.device(device)\n",
    "\n",
    "from torchvision.models import ResNet152_Weights\n",
    "from torchvision.models import resnet152\n",
    "weights = ResNet152_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f02d6",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8ec638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "#constants:\n",
    "batch_size = 64\n",
    "data_aug_type = \"4\" #what data augmentation schema to train on\n",
    "dataset = \"Dataset_2017\\\\\"\n",
    "size=(224,224)\n",
    "transforms = dataTransforms(data_aug_type,size=size,mask=False)\n",
    "\n",
    "\n",
    "Train_Dataset      = ISICClassImageDataset(dataset,\"Training\",data_aug_type=data_aug_type,size=size,bb_data_type=data_aug_type)#, target_transform=Lambda(lambda y: torch.zeros( 2, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y,dtype=torch.int64), value=1)),size=size)\n",
    "Validation_Dataset = ISICClassImageDataset(dataset,\"Validation\",data_aug_type=\"1\", size=size,bb_data_type=data_aug_type)\n",
    "Test_Dataset       = ISICClassImageDataset(dataset,\"Test\",data_aug_type=\"1\", size=size,bb_data_type=data_aug_type)\n",
    "\n",
    "data_loader_params = {\n",
    "    'batch_size': batch_size,  # Batch size for data loading\n",
    "    'num_workers': 10,  # Number of subprocesses to use for data loading\n",
    "    'persistent_workers': True,  # If True, the data loader will not shutdown the worker processes after a dataset has been consumed once. This allows to maintain the worker dataset instances alive.\n",
    "    'pin_memory': True,  # If True, the data loader will copy Tensors into CUDA pinned memory before returning them. Useful when using GPU.\n",
    "    'pin_memory_device': 'cuda' ,  # Specifies the device where the data should be loaded. Commonly set to use the GPU.\n",
    "}\n",
    "train_dataloader      = DataLoader(Train_Dataset, **data_loader_params, shuffle=True)\n",
    "validation_dataloader = DataLoader(Validation_Dataset, **data_loader_params, shuffle=True)\n",
    "test_dataloader       = DataLoader(Test_Dataset, **data_loader_params, shuffle=False,in_order=True)\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13be7a3",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd0f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_FREQUENCY = 10\n",
    "def train_one_epoch(model, training_loader, epoch_index, loss_fn, tb_writer, optimizer, lr_scheduler, scaler= None):\n",
    "    \"\"\"\n",
    "    This function will train your model and save the one that perfroms the best of validation data  \n",
    "    model: the model you wish to test  \n",
    "    train_loader: the data loader of the training dataset  \n",
    "    epoch_index: what epoch we are in for reporting purposes  \n",
    "    loss_fn: your chose loss function  \n",
    "    tb_writer: a summaryWriter used for tracking our training  \n",
    "    optimizer: the algorthim to step toward the optimal solution  \n",
    "    lr_scheduler: the lr_scheduler changes the lr dynamically as needed  \n",
    "    scaler: scales the loss dues to our use of mixed precision  \n",
    "    \"\"\"\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, targets = data\n",
    "        #send them to the model's device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #use automatic mixed precision to reduce memory consumption and allow us to run on more limited resources\n",
    "        with torch.amp.autocast(torch.device(device).type):\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        running_loss += loss\n",
    "        if scaler:#if were scaling our loss\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            old_scaler = scaler.get_scale()\n",
    "            scaler.update()\n",
    "            new_scaler = scaler.get_scale()\n",
    "            if new_scaler >= old_scaler:\n",
    "                lr_scheduler.step()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        \n",
    "        if i % REPORT_FREQUENCY == REPORT_FREQUENCY-1:\n",
    "            last_loss = running_loss / i # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a3893",
   "metadata": {},
   "source": [
    "## ResNet initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749b05c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (23): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (24): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (25): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (26): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (27): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (28): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (29): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (30): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (31): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (32): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (33): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (34): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (35): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet_model_train = True\n",
    "loss_weight = 0.5\n",
    "ResNet_model_path = 'Trained_Models\\\\ResNet152_Best_{}_{}'.format(data_aug_type,loss_weight)\n",
    "lr = 0.001\n",
    "EPOCHS = 100\n",
    "ResNet_model = resnet152(weights=weights, progress=False)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.tensor([1-loss_weight,loss_weight],device=device))\n",
    "ResNet_model.fc = nn.Linear(in_features=2048,out_features=2,bias=True)#change our number of classes to 2\n",
    "optimizer = torch.optim.SGD(ResNet_model.parameters(), lr=lr,weight_decay=0.000001)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, total_steps=EPOCHS*len(train_dataloader))\n",
    "ResNet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb2e2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 10 loss: 0.38929346203804016\n",
      "  batch 20 loss: 0.3672381043434143\n",
      "  batch 30 loss: 0.35841771960258484\n",
      "LOSS train 0.35841771960258484 valid 0.3413284718990326\n",
      "Accuracy: 0.5866666666666667 Balanced Accuracy: 0.5357404691887002\n",
      "EPOCH 2:\n",
      "  batch 10 loss: 0.37536749243736267\n",
      "  batch 20 loss: 0.351125031709671\n",
      "  batch 30 loss: 0.3432736098766327\n",
      "LOSS train 0.3432736098766327 valid 0.3197280764579773\n",
      "Accuracy: 0.6666666666666666 Balanced Accuracy: 0.5824175823879966\n",
      "EPOCH 3:\n",
      "  batch 10 loss: 0.3512769341468811\n",
      "  batch 20 loss: 0.3315422236919403\n",
      "  batch 30 loss: 0.32547515630722046\n",
      "LOSS train 0.32547515630722046 valid 0.2899967432022095\n",
      "Accuracy: 0.7 Balanced Accuracy: 0.6022516008726876\n",
      "EPOCH 4:\n",
      "  batch 10 loss: 0.3422408699989319\n",
      "  batch 20 loss: 0.31951794028282166\n",
      "  batch 30 loss: 0.31275567412376404\n",
      "LOSS train 0.31275567412376404 valid 0.30020707845687866\n",
      "Accuracy: 0.6933333333333334 Balanced Accuracy: 0.6186342592266804\n",
      "EPOCH 5:\n",
      "  batch 10 loss: 0.31633812189102173\n",
      "  batch 20 loss: 0.3014349341392517\n",
      "  batch 30 loss: 0.29343467950820923\n",
      "LOSS train 0.29343467950820923 valid 0.2875503897666931\n",
      "Accuracy: 0.6933333333333334 Balanced Accuracy: 0.604999999966\n",
      "EPOCH 6:\n",
      "  batch 10 loss: 0.30471548438072205\n",
      "  batch 20 loss: 0.28099679946899414\n",
      "  batch 30 loss: 0.2742348611354828\n",
      "LOSS train 0.2742348611354828 valid 0.2847587466239929\n",
      "Accuracy: 0.74 Balanced Accuracy: 0.6545766821163624\n",
      "EPOCH 7:\n",
      "  batch 10 loss: 0.28404131531715393\n",
      "  batch 20 loss: 0.2669498026371002\n",
      "  batch 30 loss: 0.2545164227485657\n",
      "LOSS train 0.2545164227485657 valid 0.30633053183555603\n",
      "Accuracy: 0.6333333333333333 Balanced Accuracy: 0.5875752599651176\n",
      "EPOCH 8:\n",
      "  batch 10 loss: 0.2512584328651428\n",
      "  batch 20 loss: 0.23327386379241943\n",
      "  batch 30 loss: 0.2229631245136261\n",
      "LOSS train 0.2229631245136261 valid 0.26689612865448\n",
      "Accuracy: 0.72 Balanced Accuracy: 0.622282608655482\n",
      "EPOCH 9:\n",
      "  batch 10 loss: 0.21126790344715118\n",
      "  batch 20 loss: 0.19846178591251373\n",
      "  batch 30 loss: 0.2001579850912094\n",
      "LOSS train 0.2001579850912094 valid 0.26173877716064453\n",
      "Accuracy: 0.76 Balanced Accuracy: 0.6369168356392435\n",
      "EPOCH 10:\n",
      "  batch 10 loss: 0.19511890411376953\n",
      "  batch 20 loss: 0.19139917194843292\n",
      "  batch 30 loss: 0.18572290241718292\n",
      "LOSS train 0.18572290241718292 valid 0.24785929918289185\n",
      "Accuracy: 0.7733333333333333 Balanced Accuracy: 0.6509533897621491\n",
      "EPOCH 11:\n",
      "  batch 10 loss: 0.1754518300294876\n",
      "  batch 20 loss: 0.1611168533563614\n",
      "  batch 30 loss: 0.1527973711490631\n",
      "LOSS train 0.1527973711490631 valid 0.2351849526166916\n",
      "Accuracy: 0.7533333333333333 Balanced Accuracy: 0.6304347825515528\n",
      "EPOCH 12:\n",
      "  batch 10 loss: 0.1222836971282959\n",
      "  batch 20 loss: 0.11666295677423477\n",
      "  batch 30 loss: 0.11581946164369583\n",
      "LOSS train 0.11581946164369583 valid 0.3200719356536865\n",
      "Accuracy: 0.7733333333333333 Balanced Accuracy: 0.645833333261111\n",
      "EPOCH 13:\n",
      "  batch 10 loss: 0.12438824772834778\n",
      "  batch 20 loss: 0.10199224948883057\n",
      "  batch 30 loss: 0.09518054872751236\n",
      "LOSS train 0.09518054872751236 valid 0.2967723309993744\n",
      "Accuracy: 0.74 Balanced Accuracy: 0.648729601279035\n",
      "EPOCH 14:\n",
      "  batch 10 loss: 0.06588638573884964\n",
      "  batch 20 loss: 0.05760149657726288\n",
      "  batch 30 loss: 0.0607152134180069\n",
      "LOSS train 0.0607152134180069 valid 0.2681694030761719\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7279776673828497\n",
      "EPOCH 15:\n",
      "  batch 10 loss: 0.04388554394245148\n",
      "  batch 20 loss: 0.03729218989610672\n",
      "  batch 30 loss: 0.04235999286174774\n",
      "LOSS train 0.04235999286174774 valid 0.3128999173641205\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7195716995591515\n",
      "EPOCH 16:\n",
      "  batch 10 loss: 0.03672648221254349\n",
      "  batch 20 loss: 0.038177333772182465\n",
      "  batch 30 loss: 0.03953416645526886\n",
      "LOSS train 0.03953416645526886 valid 0.4495311975479126\n",
      "Accuracy: 0.7733333333333333 Balanced Accuracy: 0.6656484961817373\n",
      "EPOCH 17:\n",
      "  batch 10 loss: 0.04036768898367882\n",
      "  batch 20 loss: 0.03806009888648987\n",
      "  batch 30 loss: 0.0355042964220047\n",
      "LOSS train 0.0355042964220047 valid 0.3703557252883911\n",
      "Accuracy: 0.7666666666666667 Balanced Accuracy: 0.6382488478586293\n",
      "EPOCH 18:\n",
      "  batch 10 loss: 0.02669345960021019\n",
      "  batch 20 loss: 0.023427505046129227\n",
      "  batch 30 loss: 0.023913227021694183\n",
      "LOSS train 0.023913227021694183 valid 0.3201586604118347\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.681451612807072\n",
      "EPOCH 19:\n",
      "  batch 10 loss: 0.014930169098079205\n",
      "  batch 20 loss: 0.014601420611143112\n",
      "  batch 30 loss: 0.013140691444277763\n",
      "LOSS train 0.013140691444277763 valid 0.3507899045944214\n",
      "Accuracy: 0.76 Balanced Accuracy: 0.648026315734072\n",
      "EPOCH 20:\n",
      "  batch 10 loss: 0.018077518790960312\n",
      "  batch 20 loss: 0.015754899010062218\n",
      "  batch 30 loss: 0.013372021727263927\n",
      "LOSS train 0.013372021727263927 valid 0.4339139461517334\n",
      "Accuracy: 0.76 Balanced Accuracy: 0.6425438595912525\n",
      "EPOCH 21:\n",
      "  batch 10 loss: 0.012912183068692684\n",
      "  batch 20 loss: 0.013671956956386566\n",
      "  batch 30 loss: 0.01543560903519392\n",
      "LOSS train 0.01543560903519392 valid 0.43388742208480835\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7180108292009709\n",
      "EPOCH 22:\n",
      "  batch 10 loss: 0.01985517516732216\n",
      "  batch 20 loss: 0.016000431030988693\n",
      "  batch 30 loss: 0.01665506698191166\n",
      "LOSS train 0.01665506698191166 valid 0.36836811900138855\n",
      "Accuracy: 0.78 Balanced Accuracy: 0.6812486014203265\n",
      "EPOCH 23:\n",
      "  batch 10 loss: 0.015854060649871826\n",
      "  batch 20 loss: 0.01313230860978365\n",
      "  batch 30 loss: 0.013659079559147358\n",
      "LOSS train 0.013659079559147358 valid 0.4463382661342621\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.7020202019421486\n",
      "EPOCH 24:\n",
      "  batch 10 loss: 0.01905124820768833\n",
      "  batch 20 loss: 0.01745712384581566\n",
      "  batch 30 loss: 0.016970736905932426\n",
      "LOSS train 0.016970736905932426 valid 0.41092583537101746\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.7113652112994652\n",
      "EPOCH 25:\n",
      "  batch 10 loss: 0.014691573567688465\n",
      "  batch 20 loss: 0.019301211461424828\n",
      "  batch 30 loss: 0.01837841607630253\n",
      "LOSS train 0.01837841607630253 valid 0.320029079914093\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7499999999\n",
      "EPOCH 26:\n",
      "  batch 10 loss: 0.015843037515878677\n",
      "  batch 20 loss: 0.020250318571925163\n",
      "  batch 30 loss: 0.018994951620697975\n",
      "LOSS train 0.018994951620697975 valid 0.40272483229637146\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7291666665722223\n",
      "EPOCH 27:\n",
      "  batch 10 loss: 0.023848311975598335\n",
      "  batch 20 loss: 0.02283891849219799\n",
      "  batch 30 loss: 0.022492706775665283\n",
      "LOSS train 0.022492706775665283 valid 0.31696391105651855\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7236024843944986\n",
      "EPOCH 28:\n",
      "  batch 10 loss: 0.017019543796777725\n",
      "  batch 20 loss: 0.02056227996945381\n",
      "  batch 30 loss: 0.01931758038699627\n",
      "LOSS train 0.01931758038699627 valid 0.5267195105552673\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7214452213625768\n",
      "EPOCH 29:\n",
      "  batch 10 loss: 0.020017415285110474\n",
      "  batch 20 loss: 0.02123955450952053\n",
      "  batch 30 loss: 0.021778320893645287\n",
      "LOSS train 0.021778320893645287 valid 0.498460054397583\n",
      "Accuracy: 0.7533333333333333 Balanced Accuracy: 0.6587301586832451\n",
      "EPOCH 30:\n",
      "  batch 10 loss: 0.01611817255616188\n",
      "  batch 20 loss: 0.015994329005479813\n",
      "  batch 30 loss: 0.0175667442381382\n",
      "LOSS train 0.0175667442381382 valid 0.46339690685272217\n",
      "Accuracy: 0.7733333333333333 Balanced Accuracy: 0.6752645502106953\n",
      "EPOCH 31:\n",
      "  batch 10 loss: 0.01284849364310503\n",
      "  batch 20 loss: 0.013422257266938686\n",
      "  batch 30 loss: 0.016714777797460556\n",
      "LOSS train 0.016714777797460556 valid 0.41921159625053406\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7105402541542802\n",
      "EPOCH 32:\n",
      "  batch 10 loss: 0.014789732173085213\n",
      "  batch 20 loss: 0.014339513145387173\n",
      "  batch 30 loss: 0.018178461119532585\n",
      "LOSS train 0.018178461119532585 valid 0.47360312938690186\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6790935671858755\n",
      "EPOCH 33:\n",
      "  batch 10 loss: 0.024248013272881508\n",
      "  batch 20 loss: 0.02308511920273304\n",
      "  batch 30 loss: 0.02052401378750801\n",
      "LOSS train 0.02052401378750801 valid 0.44720253348350525\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.7205882352420343\n",
      "EPOCH 34:\n",
      "  batch 10 loss: 0.01424319576472044\n",
      "  batch 20 loss: 0.016710501164197922\n",
      "  batch 30 loss: 0.014805890619754791\n",
      "LOSS train 0.014805890619754791 valid 0.5844883918762207\n",
      "Accuracy: 0.7666666666666667 Balanced Accuracy: 0.659390159334275\n",
      "EPOCH 35:\n",
      "  batch 10 loss: 0.008833039551973343\n",
      "  batch 20 loss: 0.008603619411587715\n",
      "  batch 30 loss: 0.009590099565684795\n",
      "LOSS train 0.009590099565684795 valid 0.37793946266174316\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7499999999\n",
      "EPOCH 36:\n",
      "  batch 10 loss: 0.00851126667112112\n",
      "  batch 20 loss: 0.007177014835178852\n",
      "  batch 30 loss: 0.01003517396748066\n",
      "LOSS train 0.01003517396748066 valid 0.47665736079216003\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6917989417422524\n",
      "EPOCH 37:\n",
      "  batch 10 loss: 0.01853197254240513\n",
      "  batch 20 loss: 0.013245348818600178\n",
      "  batch 30 loss: 0.011765271425247192\n",
      "LOSS train 0.011765271425247192 valid 0.4619368314743042\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7214452213625768\n",
      "EPOCH 38:\n",
      "  batch 10 loss: 0.008599953725934029\n",
      "  batch 20 loss: 0.007874889299273491\n",
      "  batch 30 loss: 0.007903744466602802\n",
      "LOSS train 0.007903744466602802 valid 0.4613579213619232\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 39:\n",
      "  batch 10 loss: 0.009306595660746098\n",
      "  batch 20 loss: 0.008972840383648872\n",
      "  batch 30 loss: 0.007783696986734867\n",
      "LOSS train 0.007783696986734867 valid 0.5083794593811035\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7156432747804987\n",
      "EPOCH 40:\n",
      "  batch 10 loss: 0.00794785376638174\n",
      "  batch 20 loss: 0.008373014628887177\n",
      "  batch 30 loss: 0.00759868836030364\n",
      "LOSS train 0.00759868836030364 valid 0.4493865966796875\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7499999999\n",
      "EPOCH 41:\n",
      "  batch 10 loss: 0.006478628609329462\n",
      "  batch 20 loss: 0.007546561304479837\n",
      "  batch 30 loss: 0.00758318742737174\n",
      "LOSS train 0.00758318742737174 valid 0.4864785075187683\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7236024843944986\n",
      "EPOCH 42:\n",
      "  batch 10 loss: 0.006766298320144415\n",
      "  batch 20 loss: 0.005540055222809315\n",
      "  batch 30 loss: 0.006500276271253824\n",
      "LOSS train 0.006500276271253824 valid 0.529672384262085\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7260224825866048\n",
      "EPOCH 43:\n",
      "  batch 10 loss: 0.0082754697650671\n",
      "  batch 20 loss: 0.006314572412520647\n",
      "  batch 30 loss: 0.005852599162608385\n",
      "LOSS train 0.005852599162608385 valid 0.4525768756866455\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7105402541542802\n",
      "EPOCH 44:\n",
      "  batch 10 loss: 0.008931485936045647\n",
      "  batch 20 loss: 0.007223839871585369\n",
      "  batch 30 loss: 0.0073791444301605225\n",
      "LOSS train 0.0073791444301605225 valid 0.5164254307746887\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7215909090252841\n",
      "EPOCH 45:\n",
      "  batch 10 loss: 0.0061335512436926365\n",
      "  batch 20 loss: 0.006975383963435888\n",
      "  batch 30 loss: 0.006704084575176239\n",
      "LOSS train 0.006704084575176239 valid 0.5245375037193298\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.760869565131677\n",
      "EPOCH 46:\n",
      "  batch 10 loss: 0.007497422397136688\n",
      "  batch 20 loss: 0.006161040626466274\n",
      "  batch 30 loss: 0.006675541400909424\n",
      "LOSS train 0.006675541400909424 valid 0.5179569721221924\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7521929823751219\n",
      "EPOCH 47:\n",
      "  batch 10 loss: 0.004216516390442848\n",
      "  batch 20 loss: 0.005282832309603691\n",
      "  batch 30 loss: 0.005935410037636757\n",
      "LOSS train 0.005935410037636757 valid 0.43201348185539246\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 48:\n",
      "  batch 10 loss: 0.003945411182940006\n",
      "  batch 20 loss: 0.0035102125257253647\n",
      "  batch 30 loss: 0.005235312506556511\n",
      "LOSS train 0.005235312506556511 valid 0.43556326627731323\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.760295260203433\n",
      "EPOCH 49:\n",
      "  batch 10 loss: 0.008873863145709038\n",
      "  batch 20 loss: 0.0076727005653083324\n",
      "  batch 30 loss: 0.005495002958923578\n",
      "LOSS train 0.005495002958923578 valid 0.6303260922431946\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.760295260203433\n",
      "EPOCH 50:\n",
      "  batch 10 loss: 0.005944075528532267\n",
      "  batch 20 loss: 0.005643550306558609\n",
      "  batch 30 loss: 0.00565490685403347\n",
      "LOSS train 0.00565490685403347 valid 0.39964908361434937\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 51:\n",
      "  batch 10 loss: 0.0053331018425524235\n",
      "  batch 20 loss: 0.005586401559412479\n",
      "  batch 30 loss: 0.00514315627515316\n",
      "LOSS train 0.00514315627515316 valid 0.44091761112213135\n",
      "Accuracy: 0.8466666666666667 Balanced Accuracy: 0.7602331254094125\n",
      "EPOCH 52:\n",
      "  batch 10 loss: 0.008115909062325954\n",
      "  batch 20 loss: 0.007233740296214819\n",
      "  batch 30 loss: 0.006284109316766262\n",
      "LOSS train 0.006284109316766262 valid 0.5207619667053223\n",
      "Accuracy: 0.8066666666666666 Balanced Accuracy: 0.7049689440259095\n",
      "EPOCH 53:\n",
      "  batch 10 loss: 0.004718652460724115\n",
      "  batch 20 loss: 0.006271272897720337\n",
      "  batch 30 loss: 0.005593584850430489\n",
      "LOSS train 0.005593584850430489 valid 0.5708964467048645\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7214452213625768\n",
      "EPOCH 54:\n",
      "  batch 10 loss: 0.005132789723575115\n",
      "  batch 20 loss: 0.003971274942159653\n",
      "  batch 30 loss: 0.004711467307060957\n",
      "LOSS train 0.004711467307060957 valid 0.550997257232666\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.712981744344052\n",
      "EPOCH 55:\n",
      "  batch 10 loss: 0.0037299382966011763\n",
      "  batch 20 loss: 0.005143390502780676\n",
      "  batch 30 loss: 0.005110143683850765\n",
      "LOSS train 0.005110143683850765 valid 0.4782676696777344\n",
      "Accuracy: 0.7866666666666666 Balanced Accuracy: 0.6832706766294024\n",
      "EPOCH 56:\n",
      "  batch 10 loss: 0.006384456064552069\n",
      "  batch 20 loss: 0.005885887425392866\n",
      "  batch 30 loss: 0.005030510947108269\n",
      "LOSS train 0.005030510947108269 valid 0.6272475719451904\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7215909090252841\n",
      "EPOCH 57:\n",
      "  batch 10 loss: 0.008265126496553421\n",
      "  batch 20 loss: 0.005799084901809692\n",
      "  batch 30 loss: 0.005378203000873327\n",
      "LOSS train 0.005378203000873327 valid 0.5236161351203918\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.6973684209831872\n",
      "EPOCH 58:\n",
      "  batch 10 loss: 0.00397960701957345\n",
      "  batch 20 loss: 0.004724815487861633\n",
      "  batch 30 loss: 0.005596474278718233\n",
      "LOSS train 0.005596474278718233 valid 0.6121768951416016\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7304025422849907\n",
      "EPOCH 59:\n",
      "  batch 10 loss: 0.0064713917672634125\n",
      "  batch 20 loss: 0.0052037909626960754\n",
      "  batch 30 loss: 0.0053578694351017475\n",
      "LOSS train 0.0053578694351017475 valid 0.720786452293396\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.6973684209831872\n",
      "EPOCH 60:\n",
      "  batch 10 loss: 0.005491400603204966\n",
      "  batch 20 loss: 0.0053369165398180485\n",
      "  batch 30 loss: 0.005337050184607506\n",
      "LOSS train 0.005337050184607506 valid 0.5855428576469421\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7499999999\n",
      "EPOCH 61:\n",
      "  batch 10 loss: 0.006731709931045771\n",
      "  batch 20 loss: 0.0056302789598703384\n",
      "  batch 30 loss: 0.005034186411648989\n",
      "LOSS train 0.005034186411648989 valid 0.6888329386711121\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.712981744344052\n",
      "EPOCH 62:\n",
      "  batch 10 loss: 0.004116108175367117\n",
      "  batch 20 loss: 0.00291688391007483\n",
      "  batch 30 loss: 0.00558321550488472\n",
      "LOSS train 0.00558321550488472 valid 0.44855818152427673\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.7083333332738095\n",
      "EPOCH 63:\n",
      "  batch 10 loss: 0.006293728481978178\n",
      "  batch 20 loss: 0.00597235606983304\n",
      "  batch 30 loss: 0.005981789901852608\n",
      "LOSS train 0.005981789901852608 valid 0.5593063831329346\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7185150375247329\n",
      "EPOCH 64:\n",
      "  batch 10 loss: 0.0030513086821883917\n",
      "  batch 20 loss: 0.0046317544765770435\n",
      "  batch 30 loss: 0.00560761010274291\n",
      "LOSS train 0.00560761010274291 valid 0.586982011795044\n",
      "Accuracy: 0.8 Balanced Accuracy: 0.7008928570770676\n",
      "EPOCH 65:\n",
      "  batch 10 loss: 0.0040236106142401695\n",
      "  batch 20 loss: 0.004245438147336245\n",
      "  batch 30 loss: 0.004940408747643232\n",
      "LOSS train 0.004940408747643232 valid 0.5217746496200562\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7156432747804987\n",
      "EPOCH 66:\n",
      "  batch 10 loss: 0.004932444076985121\n",
      "  batch 20 loss: 0.0041444371454417706\n",
      "  batch 30 loss: 0.0051027019508183\n",
      "LOSS train 0.0051027019508183 valid 0.49284741282463074\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7236024843944986\n",
      "EPOCH 67:\n",
      "  batch 10 loss: 0.0037174485623836517\n",
      "  batch 20 loss: 0.004057433921843767\n",
      "  batch 30 loss: 0.004495893605053425\n",
      "LOSS train 0.004495893605053425 valid 0.5596474409103394\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7422360247630878\n",
      "EPOCH 68:\n",
      "  batch 10 loss: 0.005970139056444168\n",
      "  batch 20 loss: 0.006897320970892906\n",
      "  batch 30 loss: 0.005509298760443926\n",
      "LOSS train 0.005509298760443926 valid 0.6479711532592773\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7236024843944986\n",
      "EPOCH 69:\n",
      "  batch 10 loss: 0.005284397397190332\n",
      "  batch 20 loss: 0.004131270106881857\n",
      "  batch 30 loss: 0.004318630322813988\n",
      "LOSS train 0.004318630322813988 valid 0.457213819026947\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.712981744344052\n",
      "EPOCH 70:\n",
      "  batch 10 loss: 0.0047896974720060825\n",
      "  batch 20 loss: 0.005674401298165321\n",
      "  batch 30 loss: 0.0050725191831588745\n",
      "LOSS train 0.0050725191831588745 valid 0.5126309394836426\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7399024124842819\n",
      "EPOCH 71:\n",
      "  batch 10 loss: 0.0014297874877229333\n",
      "  batch 20 loss: 0.0030526374466717243\n",
      "  batch 30 loss: 0.004455249290913343\n",
      "LOSS train 0.004455249290913343 valid 0.5860249996185303\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7422360247630878\n",
      "EPOCH 72:\n",
      "  batch 10 loss: 0.007466739974915981\n",
      "  batch 20 loss: 0.005022071767598391\n",
      "  batch 30 loss: 0.00444030063226819\n",
      "LOSS train 0.00444030063226819 valid 0.5205148458480835\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7339181285778102\n",
      "EPOCH 73:\n",
      "  batch 10 loss: 0.005786282941699028\n",
      "  batch 20 loss: 0.0050430563278496265\n",
      "  batch 30 loss: 0.004359416197985411\n",
      "LOSS train 0.004359416197985411 valid 0.4925404489040375\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 74:\n",
      "  batch 10 loss: 0.004933182615786791\n",
      "  batch 20 loss: 0.00574959721416235\n",
      "  batch 30 loss: 0.004799192771315575\n",
      "LOSS train 0.004799192771315575 valid 0.5526692867279053\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7339181285778102\n",
      "EPOCH 75:\n",
      "  batch 10 loss: 0.004801160655915737\n",
      "  batch 20 loss: 0.00410861661657691\n",
      "  batch 30 loss: 0.004550923127681017\n",
      "LOSS train 0.004550923127681017 valid 0.5683194398880005\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 76:\n",
      "  batch 10 loss: 0.00555967865511775\n",
      "  batch 20 loss: 0.0040815407410264015\n",
      "  batch 30 loss: 0.005074735265225172\n",
      "LOSS train 0.005074735265225172 valid 0.5459834337234497\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7502648304157011\n",
      "EPOCH 77:\n",
      "  batch 10 loss: 0.005434240680187941\n",
      "  batch 20 loss: 0.005229019094258547\n",
      "  batch 30 loss: 0.0044852737337350845\n",
      "LOSS train 0.0044852737337350845 valid 0.6748237609863281\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7185150375247329\n",
      "EPOCH 78:\n",
      "  batch 10 loss: 0.0062750051729381084\n",
      "  batch 20 loss: 0.005412664730101824\n",
      "  batch 30 loss: 0.005085513927042484\n",
      "LOSS train 0.005085513927042484 valid 0.5034229755401611\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7361372179723981\n",
      "EPOCH 79:\n",
      "  batch 10 loss: 0.005168973468244076\n",
      "  batch 20 loss: 0.005914442241191864\n",
      "  batch 30 loss: 0.004819040186703205\n",
      "LOSS train 0.004819040186703205 valid 0.5947393178939819\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7105402541542802\n",
      "EPOCH 80:\n",
      "  batch 10 loss: 0.006969587877392769\n",
      "  batch 20 loss: 0.005444159731268883\n",
      "  batch 30 loss: 0.0045804549008607864\n",
      "LOSS train 0.0045804549008607864 valid 0.4472953677177429\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7260224825866048\n",
      "EPOCH 81:\n",
      "  batch 10 loss: 0.004880139604210854\n",
      "  batch 20 loss: 0.004319389350712299\n",
      "  batch 30 loss: 0.005501240491867065\n",
      "LOSS train 0.005501240491867065 valid 0.4724125266075134\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7156432747804987\n",
      "EPOCH 82:\n",
      "  batch 10 loss: 0.006418661214411259\n",
      "  batch 20 loss: 0.004136587493121624\n",
      "  batch 30 loss: 0.004757317248731852\n",
      "LOSS train 0.004757317248731852 valid 0.564407229423523\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 83:\n",
      "  batch 10 loss: 0.009797644801437855\n",
      "  batch 20 loss: 0.007262122351676226\n",
      "  batch 30 loss: 0.00531686982139945\n",
      "LOSS train 0.00531686982139945 valid 0.4773889482021332\n",
      "Accuracy: 0.8133333333333334 Balanced Accuracy: 0.7156432747804987\n",
      "EPOCH 84:\n",
      "  batch 10 loss: 0.004726580809801817\n",
      "  batch 20 loss: 0.005757207982242107\n",
      "  batch 30 loss: 0.005258779972791672\n",
      "LOSS train 0.005258779972791672 valid 0.5509308576583862\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 85:\n",
      "  batch 10 loss: 0.005207520443946123\n",
      "  batch 20 loss: 0.004089046735316515\n",
      "  batch 30 loss: 0.0052006845362484455\n",
      "LOSS train 0.0052006845362484455 valid 0.49289095401763916\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 86:\n",
      "  batch 10 loss: 0.007226463872939348\n",
      "  batch 20 loss: 0.005146483425050974\n",
      "  batch 30 loss: 0.004439715761691332\n",
      "LOSS train 0.004439715761691332 valid 0.5665959715843201\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 87:\n",
      "  batch 10 loss: 0.003914060071110725\n",
      "  batch 20 loss: 0.004095553420484066\n",
      "  batch 30 loss: 0.004503842908889055\n",
      "LOSS train 0.004503842908889055 valid 0.4892534017562866\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 88:\n",
      "  batch 10 loss: 0.005463205277919769\n",
      "  batch 20 loss: 0.0052544730715453625\n",
      "  batch 30 loss: 0.004503719042986631\n",
      "LOSS train 0.004503719042986631 valid 0.5475575923919678\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7319979715202541\n",
      "EPOCH 89:\n",
      "  batch 10 loss: 0.007601719815284014\n",
      "  batch 20 loss: 0.00594310462474823\n",
      "  batch 30 loss: 0.004824723117053509\n",
      "LOSS train 0.004824723117053509 valid 0.600028395652771\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 90:\n",
      "  batch 10 loss: 0.004425146151334047\n",
      "  batch 20 loss: 0.005573415197432041\n",
      "  batch 30 loss: 0.0053065079264342785\n",
      "LOSS train 0.0053065079264342785 valid 0.42707622051239014\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7422360247630878\n",
      "EPOCH 91:\n",
      "  batch 10 loss: 0.003961049020290375\n",
      "  batch 20 loss: 0.005569039843976498\n",
      "  batch 30 loss: 0.004745290149003267\n",
      "LOSS train 0.004745290149003267 valid 0.44786959886550903\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7439607748575279\n",
      "EPOCH 92:\n",
      "  batch 10 loss: 0.007018785458058119\n",
      "  batch 20 loss: 0.0051236762665212154\n",
      "  batch 30 loss: 0.004720596596598625\n",
      "LOSS train 0.004720596596598625 valid 0.4358069896697998\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 93:\n",
      "  batch 10 loss: 0.004682021681219339\n",
      "  batch 20 loss: 0.0047021848149597645\n",
      "  batch 30 loss: 0.00410487549379468\n",
      "LOSS train 0.00410487549379468 valid 0.5644550323486328\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7422360247630878\n",
      "EPOCH 94:\n",
      "  batch 10 loss: 0.003777590114623308\n",
      "  batch 20 loss: 0.0034791913349181414\n",
      "  batch 30 loss: 0.005054528824985027\n",
      "LOSS train 0.005054528824985027 valid 0.45501798391342163\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7236024843944986\n",
      "EPOCH 95:\n",
      "  batch 10 loss: 0.005509932059794664\n",
      "  batch 20 loss: 0.005320644937455654\n",
      "  batch 30 loss: 0.004640302620828152\n",
      "LOSS train 0.004640302620828152 valid 0.4608203172683716\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7422360247630878\n",
      "EPOCH 96:\n",
      "  batch 10 loss: 0.0065500191412866116\n",
      "  batch 20 loss: 0.005888690240681171\n",
      "  batch 30 loss: 0.004766558762639761\n",
      "LOSS train 0.004766558762639761 valid 0.6122914552688599\n",
      "Accuracy: 0.8333333333333334 Balanced Accuracy: 0.7408702407830048\n",
      "EPOCH 97:\n",
      "  batch 10 loss: 0.0041993726044893265\n",
      "  batch 20 loss: 0.003934609238058329\n",
      "  batch 30 loss: 0.004078798461705446\n",
      "LOSS train 0.004078798461705446 valid 0.4757922291755676\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7304025422849907\n",
      "EPOCH 98:\n",
      "  batch 10 loss: 0.003934047184884548\n",
      "  batch 20 loss: 0.004452447406947613\n",
      "  batch 30 loss: 0.004768999759107828\n",
      "LOSS train 0.004768999759107828 valid 0.6337103247642517\n",
      "Accuracy: 0.82 Balanced Accuracy: 0.7286902286211951\n",
      "EPOCH 99:\n",
      "  batch 10 loss: 0.0047225491143763065\n",
      "  batch 20 loss: 0.00524615403264761\n",
      "  batch 30 loss: 0.004783628508448601\n",
      "LOSS train 0.004783628508448601 valid 0.4402236342430115\n",
      "Accuracy: 0.84 Balanced Accuracy: 0.7510141986964562\n",
      "EPOCH 100:\n",
      "  batch 10 loss: 0.004204584285616875\n",
      "  batch 20 loss: 0.003908669576048851\n",
      "  batch 30 loss: 0.004438712727278471\n",
      "LOSS train 0.004438712727278471 valid 0.6673328876495361\n",
      "Accuracy: 0.8266666666666667 Balanced Accuracy: 0.7339181285778102\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "if ResNet_model_train:\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = SummaryWriter('runs/ResNet{}'.format(timestamp))\n",
    "    epoch_number = 0\n",
    "\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        ResNet_model.train(True)\n",
    "        avg_loss = train_one_epoch(ResNet_model, train_dataloader, epoch_number, loss_fn, writer,optimizer,lr_scheduler,scaler)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        best_acc = 0.0\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        true_malig = 0.0\n",
    "        true_benign = 0.0\n",
    "        total_malig = 0.00000001 #prevent divide by zero\n",
    "        total_benign = 0.0          \n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        ResNet_model.eval()\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_dataloader):\n",
    "                vinputs, vtargets = vdata\n",
    "                vinputs = vinputs.to(device)\n",
    "                vtargets = vtargets.to(device)\n",
    "                #again were using AMP to allow us to train faster\n",
    "                with torch.amp.autocast(torch.device(device).type):\n",
    "                    voutputs = ResNet_model(vinputs)\n",
    "                    vloss = loss_fn(voutputs,vtargets)\n",
    "                    running_vloss += vloss\n",
    "                    _, preds = voutputs.max(1)\n",
    "                    _, vtarget = vtargets.max(1)\n",
    "                #print((preds == vtarget).sum(), preds.size(0))\n",
    "                num_correct += (preds == vtarget).sum()\n",
    "                num_samples += preds.size(0)\n",
    "                true_malig   += torch.sum(((preds == 1.0) & (vtarget == 1.0))).item()\n",
    "                true_benign  += torch.sum(((preds == 0.0) & (vtarget == 0.0))).item()\n",
    "                total_malig  += torch.sum(preds == 1.0).item()\n",
    "                total_benign += torch.sum(preds == 0.0).item()\n",
    "                #print(true_benign,total_benign)\n",
    "                #print(true_malig,total_malig)\n",
    "                \n",
    "                \n",
    "        acc = float(num_correct) / num_samples\n",
    "        bal_acc = 0.5*((true_malig/total_malig)+(true_benign/total_benign))\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "        print('Accuracy:', acc, \"Balanced Accuracy:\", bal_acc)\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.add_scalar(\"Balanced Accuracy\",bal_acc,epoch_number+1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        #AKA early stopping, a form of regularization we talked about it class\n",
    "        if bal_acc > best_acc:\n",
    "            best_acc = bal_acc\n",
    "            torch.save(ResNet_model.state_dict(), \"{}\".format(ResNet_model_path))\n",
    "\n",
    "        epoch_number += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7ed96",
   "metadata": {},
   "source": [
    "Here we can load our lowest loss model that we trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2139721",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ResNet_model_train:\n",
    "    checkpoint = torch.load(ResNet_model_path)\n",
    "    ResNet_model.load_state_dict(checkpoint)\n",
    "    ResNet_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00fdd3b",
   "metadata": {},
   "source": [
    "### Testing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069e386a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 28996, 30516, 14396, 18648, 30148, 4452) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\queue.py:179\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Disable gradient computation and reduce memory consumption.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvdata\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1297\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1296\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1298\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1299\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01me\u001b[39;00m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 28996, 30516, 14396, 18648, 30148, 4452) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "ResNet_model.eval()\n",
    "running_loss = 0.0\n",
    "best_acc = 0.0\n",
    "num_correct = 0.0\n",
    "num_samples = 0.0\n",
    "true_malig = 0.0\n",
    "true_benign = 0.0\n",
    "total_malig = 0.0\n",
    "total_benign = 0.0\n",
    "# Disable gradient computation and reduce memory consumption.\n",
    "with torch.no_grad():\n",
    "    for i, vdata in enumerate(test_dataloader):\n",
    "        inputs, targets = vdata\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        #again were using AMP to allow us to train faster\n",
    "        outputs = ResNet_model(inputs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "        running_loss += loss\n",
    "        _, preds = outputs.max(1)\n",
    "        _, target = targets.max(1)\n",
    "        num_correct += torch.sum(preds == target).item()\n",
    "        num_samples += preds.size(0)\n",
    "        #print(((preds == 0.0) == (target == 0.0)) == 0.0)\n",
    "        true_malig   += torch.sum(((preds == 1.0) & (target == 1.0))).item()\n",
    "        true_benign  += torch.sum(((preds == 0.0) & (target == 0.0))).item()\n",
    "        total_malig  += torch.sum(preds == 1.0).item()\n",
    "        total_benign += torch.sum(preds == 0.0).item()\n",
    "    acc = (num_correct / num_samples)\n",
    "print('Accuracy:', acc)\n",
    "print('Balanced Accuracy:', 0.5*((true_malig/total_malig)+(true_benign/total_benign)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
